{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24778d2",
   "metadata": {},
   "source": [
    "# Spark API Mini Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "402dcd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ffd9c",
   "metadata": {},
   "source": [
    "#### 1. Spark Dataframe Basics\n",
    "\n",
    "i. Use the starter code below to create a pandas dataframe (just run the cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8dcad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a047d0",
   "metadata": {},
   "source": [
    "ii. Convert the pandas dataframe to a spark dataframe. From this point forward, do all of your work with the spark dataframe, not the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ebe405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e739e9f",
   "metadata": {},
   "source": [
    "iii. Show the first 3 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a07581df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228ecf8",
   "metadata": {},
   "source": [
    "iv. Show the first 7 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffe886ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fea965",
   "metadata": {},
   "source": [
    "v. View a summary of the data using `.describe()`.\n",
    "> Note that `.describe` returns another dataframe, so we still have to do `.show()` at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe0dd8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+\n",
      "|summary|                 n|group|\n",
      "+-------+------------------+-----+\n",
      "|  count|                20|   20|\n",
      "|   mean|0.3664026449885216| null|\n",
      "| stddev|0.8905322898155364| null|\n",
      "|    min|-1.261605945319069|    x|\n",
      "|    max|2.1503829673811126|    z|\n",
      "+-------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f600502",
   "metadata": {},
   "source": [
    "vi. Use `.select()` to create a new dataframe with just the `n` and `abool` columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b653a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                   n|abool|\n",
      "+--------------------+-----+\n",
      "|  -0.712390662050588|false|\n",
      "|   0.753766378659703|false|\n",
      "|-0.04450307833805...|false|\n",
      "| 0.45181233874578974|false|\n",
      "|  1.3451017084510097|false|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n, df.abool).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90b625",
   "metadata": {},
   "source": [
    "vii. Use `.select()` to create a new dataframe with just the `group` and `abool` columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07dfb57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|group|abool|\n",
      "+-----+-----+\n",
      "|    z|false|\n",
      "|    x|false|\n",
      "|    z|false|\n",
      "|    y|false|\n",
      "|    z|false|\n",
      "+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.group, df.abool).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9d0c2",
   "metadata": {},
   "source": [
    "viii. Use `.select()` to create a new dataframe with the `group` column and the `abool` column renamed to `a_boolean_value`. Show the first 3 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76fc8eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|group|a_boolean_value|\n",
      "+-----+---------------+\n",
      "|    z|          false|\n",
      "|    x|          false|\n",
      "|    z|          false|\n",
      "+-----+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.group, df.abool.alias('a_boolean_value')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b1fe7",
   "metadata": {},
   "source": [
    "ix. Use `.select()` to create a new dataframe with the `group` column and the `n` column renamed to `a_numeric_value`. Show the first 6 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e5b65bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|group|     a_numeric_value|\n",
      "+-----+--------------------+\n",
      "|    z|  -0.712390662050588|\n",
      "|    x|   0.753766378659703|\n",
      "|    z|-0.04450307833805...|\n",
      "|    y| 0.45181233874578974|\n",
      "|    z|  1.3451017084510097|\n",
      "|    y|  0.5323378882945463|\n",
      "+-----+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.group, df.n.alias('a_numeric_value')).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758611f",
   "metadata": {},
   "source": [
    "#### 2. Column Manipulation\n",
    "\n",
    "i. Use the starter code above to re-create a spark dataframe. Store the spark dataframe in a variable named `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54c36b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+\n",
      "|                  n|group|abool|\n",
      "+-------------------+-----+-----+\n",
      "|-0.8850620992868307|    x|false|\n",
      "|0.07272674611277782|    x| true|\n",
      "|  -0.82751910119974|    x|false|\n",
      "| -0.591550921883219|    y|false|\n",
      "| -2.186215625579764|    y| true|\n",
      "+-------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae4e84",
   "metadata": {},
   "source": [
    "ii. Use `select()` to add 4 to the `n` column. Show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2eec5025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          n_plus_4|\n",
      "+------------------+\n",
      "|3.1149379007131692|\n",
      "| 4.072726746112778|\n",
      "|  3.17248089880026|\n",
      "| 3.408449078116781|\n",
      "|1.8137843744202362|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(expr('n + 4 AS n_plus_4'))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5923f8",
   "metadata": {},
   "source": [
    "iii. Subtract 5 from the `n` column and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c3891f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         n_minus_5|\n",
      "+------------------+\n",
      "|-5.885062099286831|\n",
      "|-4.927273253887222|\n",
      "| -5.82751910119974|\n",
      "|-5.591550921883219|\n",
      "|-7.186215625579764|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(expr('n -5 AS n_minus_5'))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e895e7d2",
   "metadata": {},
   "source": [
    "iv. Multiply the `n` column by 2. View the results along with the original numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a58e8bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          n_times_2|\n",
      "+-------------------+\n",
      "|-1.7701241985736613|\n",
      "|0.14545349222555565|\n",
      "|  -1.65503820239948|\n",
      "| -1.183101843766438|\n",
      "| -4.372431251159528|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(expr('n * 2 AS n_times_2'))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ff1c9f",
   "metadata": {},
   "source": [
    "v. Add a new column named `n2` that is the `n` value multiplied by -1. Show the first 4 rows of your dataframe. You should see the original `n` value as well as `n2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37a1b15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|                  n|                  n2|\n",
      "+-------------------+--------------------+\n",
      "|-0.8850620992868307|  0.8850620992868307|\n",
      "|0.07272674611277782|-0.07272674611277782|\n",
      "|  -0.82751910119974|    0.82751910119974|\n",
      "| -0.591550921883219|   0.591550921883219|\n",
      "+-------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(expr('n'),\n",
    "           expr('n * -1 AS n2'))\n",
    ").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a273fb",
   "metadata": {},
   "source": [
    "vi. Add a new column named `n3` that is the `n` value squared. Show the first 5 rows of your dataframe. You should see both `n`, `n2`, and `n3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec2353fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+\n",
      "|                  n|                  n2|                  n3|\n",
      "+-------------------+--------------------+--------------------+\n",
      "|-0.8850620992868307|  0.8850620992868307|  0.7833349195940117|\n",
      "|0.07272674611277782|-0.07272674611277782|0.005289179600152444|\n",
      "|  -0.82751910119974|    0.82751910119974|  0.6847878628504256|\n",
      "| -0.591550921883219|   0.591550921883219| 0.34993249318088626|\n",
      "| -2.186215625579764|   2.186215625579764|   4.779538761529118|\n",
      "+-------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(expr('n'),\n",
    "           expr('n * -1 AS n2'),\n",
    "           expr('pow(n, 2) AS n3'))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f535e4",
   "metadata": {},
   "source": [
    "vii. What happens when you run the code below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7deed9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(group + abool)'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group + df.abool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d00b7",
   "metadata": {},
   "source": [
    "**A**: A Column object is produced that represents the transformation of adding together the `group` and `abool` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa6499",
   "metadata": {},
   "source": [
    "viii. What happens when you run the code below? What is the difference between this and the previous code sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd353193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '(CAST(group AS DOUBLE) + abool)' due to data type mismatch: differing types in '(CAST(group AS DOUBLE) + abool)' (double and boolean).;\n'Project [unresolvedalias((cast(group#739 as double) + abool#740), Some(org.apache.spark.sql.Column$$Lambda$3381/0x00000008013b4040@6628ea39))]\n+- LogicalRDD [n#738, group#739, abool#740], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g3/kfw_0xts4c778bttx6jrkqm00000gn/T/ipykernel_33838/2226179756.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \"\"\"\n\u001b[0;32m-> 1685\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '(CAST(group AS DOUBLE) + abool)' due to data type mismatch: differing types in '(CAST(group AS DOUBLE) + abool)' (double and boolean).;\n'Project [unresolvedalias((cast(group#739 as double) + abool#740), Some(org.apache.spark.sql.Column$$Lambda$3381/0x00000008013b4040@6628ea39))]\n+- LogicalRDD [n#738, group#739, abool#740], false\n"
     ]
    }
   ],
   "source": [
    "df.select(df.group + df.abool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803ce4e",
   "metadata": {},
   "source": [
    "An error is produced referencing the incompatible types. Unlike the previous code sample, this one is done within the context of a `.select`, so even though there are still no values produced (we haven't invoked an action yet), spark is aware that the types are incompatible.\n",
    "\n",
    "ix. Try adding various other columns together. What are the results of combining the different data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "750108ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 'double'), ('group', 'string'), ('abool', 'boolean')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "72ac86b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(n + group)'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.n + df.group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ad40192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'(n + abool)'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.n + df.abool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff77c51",
   "metadata": {},
   "source": [
    "#### 3. Type Casting\n",
    "\n",
    "i. Use the starter code above to re-create a spark dataframe named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1a9e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+\n",
      "|                  n|group|abool|\n",
      "+-------------------+-----+-----+\n",
      "|-0.8850620992868307|    x|false|\n",
      "|0.07272674611277782|    x| true|\n",
      "|  -0.82751910119974|    x|false|\n",
      "| -0.591550921883219|    y|false|\n",
      "| -2.186215625579764|    y| true|\n",
      "+-------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbb20cc",
   "metadata": {},
   "source": [
    "ii. Use `.printSchema()` to view the datatypes in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ecadccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- n: double (nullable = true)\n",
      " |-- group: string (nullable = true)\n",
      " |-- abool: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22eabe",
   "metadata": {},
   "source": [
    "iii. Use `.dtypes` to view the datatypes in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfe43beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 'double'), ('group', 'string'), ('abool', 'boolean')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a8621a",
   "metadata": {},
   "source": [
    "iv. What is the difference between the two code samples below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "94db80fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'CAST(abool AS INT)'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.abool.cast('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "009fb5d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|abool|\n",
      "+-----+\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    1|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.abool.cast('int')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76990605",
   "metadata": {},
   "source": [
    "**A:** One is a creating a Column and one is using that same column in a `.select()` in order to view the results of the cast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5556951",
   "metadata": {},
   "source": [
    "v. Use `.select()` and `.cast()` to convert the abool column to an integer type. View the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ad3a2263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|abool|\n",
      "+-----+\n",
      "|    0|\n",
      "|    1|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.abool.cast('int')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35549949",
   "metadata": {},
   "source": [
    "vi. Convert the `group` column to a integer data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28e2e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|group|\n",
      "+-----+\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.group.cast('int')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8f127",
   "metadata": {},
   "source": [
    "vii. Convert the `n` column to a integer data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "822ddf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  n|\n",
      "+---+\n",
      "|  0|\n",
      "|  0|\n",
      "|  0|\n",
      "|  0|\n",
      "| -2|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n.cast('int')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0321303",
   "metadata": {},
   "source": [
    "viii. Convert the `abool` column to a string data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53353b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|abool|\n",
      "+-----+\n",
      "|false|\n",
      "| true|\n",
      "|false|\n",
      "|false|\n",
      "| true|\n",
      "+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.abool.cast('string')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a7bf7e",
   "metadata": {},
   "source": [
    "#### 4. Built-in Functions\n",
    "\n",
    "i. Use the starter code above to re-create a spark dataframe named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d91e64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| -0.7209996734353815|    z| true|\n",
      "|  0.5622617060581323|    x|false|\n",
      "| -0.3148580761325759|    z| true|\n",
      "|-0.42989708186880404|    z| true|\n",
      "|  0.8149954430712237|    x| true|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113e26b",
   "metadata": {},
   "source": [
    "ii. Import the necessary functions from `pyspark.sql.functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bcd19845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b9dfd",
   "metadata": {},
   "source": [
    "iii. Find the highest `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d891af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|max value of n|\n",
      "+--------------+\n",
      "|          1.75|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(round(max('n'), 2).alias('max value of n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6944b5",
   "metadata": {},
   "source": [
    "iv. Find the lowest `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4f9b2176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|min value of n|\n",
      "+--------------+\n",
      "|         -2.19|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(round(min('n'), 2).alias('min value of n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc61f6",
   "metadata": {},
   "source": [
    "v. Find the average `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "05ea341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|average value of n|\n",
      "+------------------+\n",
      "|               0.0|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(round(avg('n'), 2).alias('average value of n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba73026",
   "metadata": {},
   "source": [
    "vi. Use `concat()` to change the group column to say \"Group: x\" or \"Group: y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03bbaa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----+\n",
      "|                   n|group: x|abool|\n",
      "+--------------------+--------+-----+\n",
      "| -0.7209996734353815|       z| true|\n",
      "|  0.5622617060581323|       x|false|\n",
      "| -0.3148580761325759|       z| true|\n",
      "|-0.42989708186880404|       z| true|\n",
      "|  0.8149954430712237|       x| true|\n",
      "+--------------------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed('group', 'group: x').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea48b3c9",
   "metadata": {},
   "source": [
    "vii. Use `concat()` to combine the `n` and `group` columns to produce results that look like this: \"x: -1.432\" or \"z: 2.352\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "759ffa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|group: n  |\n",
      "+----------+\n",
      "|z: -0.721 |\n",
      "|x: 0.5623 |\n",
      "|z: -0.3149|\n",
      "|z: -0.4299|\n",
      "|x: 0.815  |\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df\n",
    " .select(concat(df.group, \n",
    "                lit(': '), \n",
    "                round(df.n, \n",
    "                4))\n",
    "                .alias('group: n')).show(5, truncate = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c6e50",
   "metadata": {},
   "source": [
    "#### 5. When / Otherwise\n",
    "\n",
    "i. Use the starter code above to re-create a spark dataframe named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "03ecf982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  0.5345941466677115|    x| true|\n",
      "|  0.8231227651701564|    x|false|\n",
      "|  0.8862891040333676|    x|false|\n",
      "| 0.17266171218872037|    z| true|\n",
      "|-0.21312889268996238|    y|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5729d",
   "metadata": {},
   "source": [
    "ii. Use `when()` and `.otherwise()` to create a column that contains the text \"It is true\" when abool is true and \"It is false\"\" when abool is false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "178a0fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------+\n",
      "|abool| Is it t/f?|\n",
      "+-----+-----------+\n",
      "| true| It is true|\n",
      "|false|It is false|\n",
      "|false|It is false|\n",
      "| true| It is true|\n",
      "|false|It is false|\n",
      "+-----+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(df.abool,\n",
    "           when(df.abool == 'true', 'It is true')\n",
    "           .otherwise('It is false')\n",
    "           .alias('Is it t/f?')).show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7150a4d",
   "metadata": {},
   "source": [
    "iii. Create a column that contains 0 if n is less than 0, otherwise, the original `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5d3c2a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------+\n",
      "|                   n|zero if n is less than 0|\n",
      "+--------------------+------------------------+\n",
      "|  0.5345941466677115|      0.5345941466677115|\n",
      "|  0.8231227651701564|      0.8231227651701564|\n",
      "|  0.8862891040333676|      0.8862891040333676|\n",
      "| 0.17266171218872037|     0.17266171218872037|\n",
      "|-0.21312889268996238|                     0.0|\n",
      "+--------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.select(df.n,\n",
    "           when(df.n < 0, 0)\n",
    "           .otherwise(df.n)\n",
    "           .alias('zero if n is less than 0')).show(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a59fcb",
   "metadata": {},
   "source": [
    "#### 6. Filter / Where\n",
    "\n",
    "i. Use the starter code above to re-create a spark dataframe named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fcfffa8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  1.2636494824990419|    z| true|\n",
      "|  1.5708990002014271|    y|false|\n",
      "| -1.2615486912059428|    x|false|\n",
      "|-0.07508917570719996|    y| true|\n",
      "|  0.8501070283110412|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd3450",
   "metadata": {},
   "source": [
    "ii. Use `.filter()` or `.where()` to select just the rows where the group is y and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4123fc04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  1.5708990002014271|    y|false|\n",
      "|-0.07508917570719996|    y| true|\n",
      "| -0.8673479540502249|    y| true|\n",
      "| -0.7749046025022026|    y|false|\n",
      "|  1.2732503628768688|    y| true|\n",
      "|  0.9105807193557125|    y| true|\n",
      "| -0.5484703109458559|    y|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.filter(df.group == 'y').show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "610e1458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  1.5708990002014271|    y|false|\n",
      "|-0.07508917570719996|    y| true|\n",
      "| -0.8673479540502249|    y| true|\n",
      "| -0.7749046025022026|    y|false|\n",
      "|  1.2732503628768688|    y| true|\n",
      "|  0.9105807193557125|    y| true|\n",
      "| -0.5484703109458559|    y|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df.where(df.group == 'y').show()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9791666f",
   "metadata": {},
   "source": [
    "iii. Select just the columns where the `abool` column is false and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6aebdc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+\n",
      "|                  n|group|abool|\n",
      "+-------------------+-----+-----+\n",
      "| 1.5708990002014271|    y|false|\n",
      "|-1.2615486912059428|    x|false|\n",
      "| 0.8501070283110412|    z|false|\n",
      "| 0.7731666960765334|    z|false|\n",
      "|-0.7749046025022026|    y|false|\n",
      "| 1.0112322458862237|    x|false|\n",
      "| 0.9416459862960309|    x|false|\n",
      "|-0.7699411266400571|    z|false|\n",
      "|-1.1303179237441572|    x|false|\n",
      "| 0.9254890406588132|    x|false|\n",
      "|-0.5484703109458559|    y|false|\n",
      "|-0.9795224677574916|    z|false|\n",
      "+-------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.abool == 'false').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b79d8f8",
   "metadata": {},
   "source": [
    "iv. Find the columns where the group column is not y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9c30b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  1.2636494824990419|    z| true|\n",
      "| -1.2615486912059428|    x|false|\n",
      "|  0.8501070283110412|    z|false|\n",
      "| -0.9150316963547941|    x| true|\n",
      "|  0.7731666960765334|    z|false|\n",
      "|  1.0112322458862237|    x|false|\n",
      "|  0.9416459862960309|    x|false|\n",
      "| -0.7699411266400571|    z|false|\n",
      "| -1.1303179237441572|    x|false|\n",
      "|  0.9254890406588132|    x|false|\n",
      "|-0.04059007575872...|    x| true|\n",
      "| -1.6774958544832872|    z| true|\n",
      "| -0.9795224677574916|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.group != 'y').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e87b9",
   "metadata": {},
   "source": [
    "v. Find the columns where `n` is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c7c2aa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+-----+\n",
      "|                 n|group|abool|\n",
      "+------------------+-----+-----+\n",
      "|1.2636494824990419|    z| true|\n",
      "|1.5708990002014271|    y|false|\n",
      "|0.8501070283110412|    z|false|\n",
      "|0.7731666960765334|    z|false|\n",
      "|1.0112322458862237|    x|false|\n",
      "|0.9416459862960309|    x|false|\n",
      "|0.9254890406588132|    x|false|\n",
      "|1.2732503628768688|    y| true|\n",
      "|0.9105807193557125|    y| true|\n",
      "+------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.n > 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abae76e",
   "metadata": {},
   "source": [
    "vi. Find the columns where `abool` is true and the group column is z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3aed5a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+\n",
      "|                  n|group|abool|\n",
      "+-------------------+-----+-----+\n",
      "| 1.2636494824990419|    z| true|\n",
      "|-1.6774958544832872|    z| true|\n",
      "+-------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.abool == 'true').where(df.group == 'z').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d539fa2",
   "metadata": {},
   "source": [
    "vii. Find the columns where `abool` is true or the `group` column is z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "14bf1fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  1.2636494824990419|    z| true|\n",
      "|-0.07508917570719996|    y| true|\n",
      "|  0.8501070283110412|    z|false|\n",
      "| -0.9150316963547941|    x| true|\n",
      "| -0.8673479540502249|    y| true|\n",
      "|  0.7731666960765334|    z|false|\n",
      "| -0.7699411266400571|    z|false|\n",
      "|  1.2732503628768688|    y| true|\n",
      "|-0.04059007575872...|    x| true|\n",
      "|  0.9105807193557125|    y| true|\n",
      "| -1.6774958544832872|    z| true|\n",
      "| -0.9795224677574916|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where((df.abool == 'true')|(df.group == 'z')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e28969",
   "metadata": {},
   "source": [
    "viii. Find the columns where `abool` is false and `n` is less than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "30ecb663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+\n",
      "|                  n|group|abool|\n",
      "+-------------------+-----+-----+\n",
      "|-1.2615486912059428|    x|false|\n",
      "| 0.8501070283110412|    z|false|\n",
      "| 0.7731666960765334|    z|false|\n",
      "|-0.7749046025022026|    y|false|\n",
      "| 0.9416459862960309|    x|false|\n",
      "|-0.7699411266400571|    z|false|\n",
      "|-1.1303179237441572|    x|false|\n",
      "| 0.9254890406588132|    x|false|\n",
      "|-0.5484703109458559|    y|false|\n",
      "|-0.9795224677574916|    z|false|\n",
      "+-------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.abool == 'false').filter(df.n < 1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a1457a",
   "metadata": {},
   "source": [
    "ix. Find the columns where `abool` is false or `n` is less than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1cab71e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  1.5708990002014271|    y|false|\n",
      "| -1.2615486912059428|    x|false|\n",
      "|-0.07508917570719996|    y| true|\n",
      "|  0.8501070283110412|    z|false|\n",
      "| -0.9150316963547941|    x| true|\n",
      "| -0.8673479540502249|    y| true|\n",
      "|  0.7731666960765334|    z|false|\n",
      "| -0.7749046025022026|    y|false|\n",
      "|  1.0112322458862237|    x|false|\n",
      "|  0.9416459862960309|    x|false|\n",
      "| -0.7699411266400571|    z|false|\n",
      "| -1.1303179237441572|    x|false|\n",
      "|  0.9254890406588132|    x|false|\n",
      "|-0.04059007575872...|    x| true|\n",
      "|  0.9105807193557125|    y| true|\n",
      "| -1.6774958544832872|    z| true|\n",
      "| -0.5484703109458559|    y|false|\n",
      "| -0.9795224677574916|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where((df.abool == 'false')|(df.n < 1)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2667721b",
   "metadata": {},
   "source": [
    "#### 7. Sorting\n",
    "\n",
    "i. Use the starter code above to re-create a spark dataframe named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cffa548d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  1.2690580976875576|    x| true|\n",
      "|  0.2572490050399525|    z|false|\n",
      "| -1.6642564360602479|    y|false|\n",
      "| -0.1217464334245328|    y|false|\n",
      "|-0.44151223119024857|    x| true|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032a4315",
   "metadata": {},
   "source": [
    "ii. Sort by the `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1cb4d70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| -1.6642564360602479|    y|false|\n",
      "| -1.5509569211976624|    x| true|\n",
      "| -1.4141544662915098|    z|false|\n",
      "| -1.2768778466596493|    x| true|\n",
      "| -1.0669628403806435|    y|false|\n",
      "| -0.6625811650314397|    x| true|\n",
      "|-0.44151223119024857|    x| true|\n",
      "| -0.3848490502028002|    y|false|\n",
      "| -0.3051810275934747|    z| true|\n",
      "| -0.1217464334245328|    y|false|\n",
      "| 0.01997092245414585|    y| true|\n",
      "|0.041447402165011596|    y| true|\n",
      "| 0.12673002941390707|    x|false|\n",
      "|  0.2572490050399525|    z|false|\n",
      "|  0.5253295997343811|    z| true|\n",
      "|  0.7435452461317569|    z| true|\n",
      "|  0.8628168935353443|    z| true|\n",
      "|  0.9552466924396553|    x|false|\n",
      "|  1.2690580976875576|    x| true|\n",
      "|  3.4011057189806557|    z| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.n).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e4536",
   "metadata": {},
   "source": [
    "iii. Sort by the `group` value, both ascending and descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0b5d4945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|-0.44151223119024857|    x| true|\n",
      "|  1.2690580976875576|    x| true|\n",
      "| 0.12673002941390707|    x|false|\n",
      "|  0.9552466924396553|    x|false|\n",
      "| -0.6625811650314397|    x| true|\n",
      "| -1.5509569211976624|    x| true|\n",
      "| -1.2768778466596493|    x| true|\n",
      "| -1.0669628403806435|    y|false|\n",
      "| -0.3848490502028002|    y|false|\n",
      "| 0.01997092245414585|    y| true|\n",
      "| -1.6642564360602479|    y|false|\n",
      "| -0.1217464334245328|    y|false|\n",
      "|0.041447402165011596|    y| true|\n",
      "| -0.3051810275934747|    z| true|\n",
      "|  3.4011057189806557|    z| true|\n",
      "|  0.7435452461317569|    z| true|\n",
      "|  0.2572490050399525|    z|false|\n",
      "|  0.5253295997343811|    z| true|\n",
      "|  0.8628168935353443|    z| true|\n",
      "| -1.4141544662915098|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(asc(df.group)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1201ab57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| -1.4141544662915098|    z|false|\n",
      "| -0.3051810275934747|    z| true|\n",
      "|  0.7435452461317569|    z| true|\n",
      "|  3.4011057189806557|    z| true|\n",
      "|  0.5253295997343811|    z| true|\n",
      "|  0.8628168935353443|    z| true|\n",
      "|  0.2572490050399525|    z|false|\n",
      "| 0.01997092245414585|    y| true|\n",
      "| -0.3848490502028002|    y|false|\n",
      "| -1.6642564360602479|    y|false|\n",
      "| -0.1217464334245328|    y|false|\n",
      "| -1.0669628403806435|    y|false|\n",
      "|0.041447402165011596|    y| true|\n",
      "| 0.12673002941390707|    x|false|\n",
      "|-0.44151223119024857|    x| true|\n",
      "| -0.6625811650314397|    x| true|\n",
      "| -1.2768778466596493|    x| true|\n",
      "|  1.2690580976875576|    x| true|\n",
      "|  0.9552466924396553|    x|false|\n",
      "| -1.5509569211976624|    x| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(desc(df.group)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ef1e95",
   "metadata": {},
   "source": [
    "iv. Sort by the `group` value first, then, within each group, sort by `n` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "483a8b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| -1.5509569211976624|    x| true|\n",
      "| -1.2768778466596493|    x| true|\n",
      "| -0.6625811650314397|    x| true|\n",
      "|-0.44151223119024857|    x| true|\n",
      "| 0.12673002941390707|    x|false|\n",
      "|  0.9552466924396553|    x|false|\n",
      "|  1.2690580976875576|    x| true|\n",
      "| -1.6642564360602479|    y|false|\n",
      "| -1.0669628403806435|    y|false|\n",
      "| -0.3848490502028002|    y|false|\n",
      "| -0.1217464334245328|    y|false|\n",
      "| 0.01997092245414585|    y| true|\n",
      "|0.041447402165011596|    y| true|\n",
      "| -1.4141544662915098|    z|false|\n",
      "| -0.3051810275934747|    z| true|\n",
      "|  0.2572490050399525|    z|false|\n",
      "|  0.5253295997343811|    z| true|\n",
      "|  0.7435452461317569|    z| true|\n",
      "|  0.8628168935353443|    z| true|\n",
      "|  3.4011057189806557|    z| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.group, df.n).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ad917",
   "metadata": {},
   "source": [
    "v. Sort by `abool`, `group`, and `n`. Does it matter in what order you specify the columns when sorting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "984d8736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| 0.12673002941390707|    x|false|\n",
      "|  0.9552466924396553|    x|false|\n",
      "| -1.6642564360602479|    y|false|\n",
      "| -1.0669628403806435|    y|false|\n",
      "| -0.3848490502028002|    y|false|\n",
      "| -0.1217464334245328|    y|false|\n",
      "| -1.4141544662915098|    z|false|\n",
      "|  0.2572490050399525|    z|false|\n",
      "| -1.5509569211976624|    x| true|\n",
      "| -1.2768778466596493|    x| true|\n",
      "| -0.6625811650314397|    x| true|\n",
      "|-0.44151223119024857|    x| true|\n",
      "|  1.2690580976875576|    x| true|\n",
      "| 0.01997092245414585|    y| true|\n",
      "|0.041447402165011596|    y| true|\n",
      "| -0.3051810275934747|    z| true|\n",
      "|  0.5253295997343811|    z| true|\n",
      "|  0.7435452461317569|    z| true|\n",
      "|  0.8628168935353443|    z| true|\n",
      "|  3.4011057189806557|    z| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.abool, df.group, df.n).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f3f63d0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| -1.6642564360602479|    y|false|\n",
      "| -1.5509569211976624|    x| true|\n",
      "| -1.4141544662915098|    z|false|\n",
      "| -1.2768778466596493|    x| true|\n",
      "| -1.0669628403806435|    y|false|\n",
      "| -0.6625811650314397|    x| true|\n",
      "|-0.44151223119024857|    x| true|\n",
      "| -0.3848490502028002|    y|false|\n",
      "| -0.3051810275934747|    z| true|\n",
      "| -0.1217464334245328|    y|false|\n",
      "| 0.01997092245414585|    y| true|\n",
      "|0.041447402165011596|    y| true|\n",
      "| 0.12673002941390707|    x|false|\n",
      "|  0.2572490050399525|    z|false|\n",
      "|  0.5253295997343811|    z| true|\n",
      "|  0.7435452461317569|    z| true|\n",
      "|  0.8628168935353443|    z| true|\n",
      "|  0.9552466924396553|    x|false|\n",
      "|  1.2690580976875576|    x| true|\n",
      "|  3.4011057189806557|    z| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.n, df.abool, df.group).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7116479d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| -1.5509569211976624|    x| true|\n",
      "| -1.2768778466596493|    x| true|\n",
      "| -0.6625811650314397|    x| true|\n",
      "|-0.44151223119024857|    x| true|\n",
      "| 0.12673002941390707|    x|false|\n",
      "|  0.9552466924396553|    x|false|\n",
      "|  1.2690580976875576|    x| true|\n",
      "| -1.6642564360602479|    y|false|\n",
      "| -1.0669628403806435|    y|false|\n",
      "| -0.3848490502028002|    y|false|\n",
      "| -0.1217464334245328|    y|false|\n",
      "| 0.01997092245414585|    y| true|\n",
      "|0.041447402165011596|    y| true|\n",
      "| -1.4141544662915098|    z|false|\n",
      "| -0.3051810275934747|    z| true|\n",
      "|  0.2572490050399525|    z|false|\n",
      "|  0.5253295997343811|    z| true|\n",
      "|  0.7435452461317569|    z| true|\n",
      "|  0.8628168935353443|    z| true|\n",
      "|  3.4011057189806557|    z| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.group, df.n, df.abool).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24722352",
   "metadata": {},
   "source": [
    "**A:** It does matter as it determines in what order they will be sorted. When the values for the first specified column are the same, the next specified column will determine sort order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f34487",
   "metadata": {},
   "source": [
    "#### 8. Spark SQL\n",
    "\n",
    "i. Use the starter code above to re-create a spark dataframe named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f1c9bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|-0.01842180913757...|    y| true|\n",
      "| 0.10767464455391365|    z| true|\n",
      "|-0.15579970816999872|    y| true|\n",
      "| -1.4634777566193453|    x|false|\n",
      "| -0.5334945027167617|    x|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afedc2cc",
   "metadata": {},
   "source": [
    "ii. Turn your dataframe into a table that can be queried with spark SQL. Name the table `my_df`. Answer the rest of the questions in this section with a spark sql query (`spark.sql`) against `my_df`. After each step, view the first 7 records from the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c4441178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('my_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae36cd3",
   "metadata": {},
   "source": [
    "iii. Write a query that shows all of the columns from your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "afa1c3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|-0.01842180913757...|    y| true|\n",
      "| 0.10767464455391365|    z| true|\n",
      "|-0.15579970816999872|    y| true|\n",
      "| -1.4634777566193453|    x|false|\n",
      "| -0.5334945027167617|    x|false|\n",
      "| -1.9323560015091858|    z| true|\n",
      "|  0.9399792195744116|    x| true|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT * FROM my_df\n",
    "\"\"\").show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686512e4",
   "metadata": {},
   "source": [
    "iv. Write a query that shows just the `n` and `abool` columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7555c1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----+\n",
      "|n                    |abool|\n",
      "+---------------------+-----+\n",
      "|-0.018421809137576996|true |\n",
      "|0.10767464455391365  |true |\n",
      "|-0.15579970816999872 |true |\n",
      "|-1.4634777566193453  |false|\n",
      "|-0.5334945027167617  |false|\n",
      "|-1.9323560015091858  |true |\n",
      "|0.9399792195744116   |true |\n",
      "+---------------------+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT my_df.n, my_df.abool FROM my_df\n",
    "\"\"\").show(7, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebbd2e2",
   "metadata": {},
   "source": [
    "v. Write a query that shows just the `n` and `group` columns. Rename the `group` column to `g`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d14b679e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---+\n",
      "|n                    |g  |\n",
      "+---------------------+---+\n",
      "|-0.018421809137576996|y  |\n",
      "|0.10767464455391365  |z  |\n",
      "|-0.15579970816999872 |y  |\n",
      "|-1.4634777566193453  |x  |\n",
      "|-0.5334945027167617  |x  |\n",
      "|-1.9323560015091858  |z  |\n",
      "|0.9399792195744116   |x  |\n",
      "+---------------------+---+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT my_df.n, my_df.group AS g FROM my_df\n",
    "\"\"\").show(7, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64198546",
   "metadata": {},
   "source": [
    "vi. Write a query that selects `n`, and creates two new columns: `n2`, the original `n` values halved, and `n3`: the original `n` values minus 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f1f48165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------------------+--------------------+\n",
      "|n                    |n2                   |n3                  |\n",
      "+---------------------+---------------------+--------------------+\n",
      "|-0.018421809137576996|-0.009210904568788498|-1.018421809137577  |\n",
      "|0.10767464455391365  |0.053837322276956825 |-0.8923253554460864 |\n",
      "|-0.15579970816999872 |-0.07789985408499936 |-1.1557997081699987 |\n",
      "|-1.4634777566193453  |-0.7317388783096727  |-2.463477756619345  |\n",
      "|-0.5334945027167617  |-0.26674725135838084 |-1.5334945027167617 |\n",
      "|-1.9323560015091858  |-0.9661780007545929  |-2.932356001509186  |\n",
      "|0.9399792195744116   |0.4699896097872058   |-0.06002078042558845|\n",
      "+---------------------+---------------------+--------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT my_df.n, my_df.n/2 AS n2, my_df.n - 1 AS n3 FROM my_df\n",
    "\"\"\").show(7, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881c247",
   "metadata": {},
   "source": [
    "vii. What happens if you make a SQL syntax error in your query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d70fa8f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'my_df.n' given input columns: []; line 2 pos 7;\n'Project ['my_df.n, ('my_df.n / 2) AS n2#1722, ('my_df.n - 1) AS n3#1723]\n+- OneRowRelation\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g3/kfw_0xts4c778bttx6jrkqm00000gn/T/ipykernel_33838/3124937110.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m spark.sql(\"\"\"\n\u001b[1;32m      2\u001b[0m \u001b[0mSELECT\u001b[0m \u001b[0mmy_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mn3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \"\"\").show(7, truncate = False)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'my_df.n' given input columns: []; line 2 pos 7;\n'Project ['my_df.n, ('my_df.n / 2) AS n2#1722, ('my_df.n - 1) AS n3#1723]\n+- OneRowRelation\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT my_df.n, my_df.n/2 AS n2, my_df.n - 1 AS n3\n",
    "\"\"\").show(7, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6875af",
   "metadata": {},
   "source": [
    "#### 9. Aggregating\n",
    "\n",
    "i. Use the starter code above to re-create a spark dataframe named `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6e8a169e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "| -0.5248595180693141|    y|false|\n",
      "| 0.06669160250137181|    y| true|\n",
      "|  2.8140657814433814|    z| true|\n",
      "|   0.903404851948607|    y|false|\n",
      "|-0.25281199164778545|    y|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pandas_dataframe = pd.DataFrame({\n",
    "    \"n\": np.random.randn(20),\n",
    "    \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "    \"abool\": np.random.choice([True, False], 20),\n",
    "})\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7effd53f",
   "metadata": {},
   "source": [
    "ii. What is the average `n` value for each group in the `group` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "13bfdd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|group|avg value of n|\n",
      "+-----+--------------+\n",
      "|    y|        0.4138|\n",
      "|    z|        0.3919|\n",
      "|    x|        1.2398|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.group).agg(round(avg(df.n), 4).alias('avg value of n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27a4b6",
   "metadata": {},
   "source": [
    "iii. What is the maximum `n` value for each group in the `group` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b4ac476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|group|max value of n|\n",
      "+-----+--------------+\n",
      "|    y|           1.9|\n",
      "|    z|          2.81|\n",
      "|    x|          2.41|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.group).agg(round(max(df.n), 2).alias('max value of n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923acac0",
   "metadata": {},
   "source": [
    "iv. What is the minimum `n` value by `abool`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8866b4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|group|min value of n|\n",
      "+-----+--------------+\n",
      "|    y|         -0.55|\n",
      "|    z|         -0.97|\n",
      "|    x|         -0.05|\n",
      "+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.group).agg(round(min(df.n), 2).alias('min value of n')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ff801d",
   "metadata": {},
   "source": [
    "v. What is the average `n` value for each unique combination of the `group` and `abool` column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c2c13a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------------+\n",
      "|group|abool|avg value of n|\n",
      "+-----+-----+--------------+\n",
      "|    y|false|           0.2|\n",
      "|    y| true|          0.67|\n",
      "|    z| true|          0.73|\n",
      "|    x|false|          1.51|\n",
      "|    x| true|          1.15|\n",
      "|    z|false|         -0.97|\n",
      "+-----+-----+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/14 16:46:43 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1523153 ms exceeds timeout 120000 ms\n",
      "22/02/14 16:46:44 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df.group, df.abool).agg(round(avg(df.n), 2).alias('avg value of n')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2248e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
